{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d9b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TASK INCREMENTAL CONTINUAL LEARNING WITH FISHER INFORMATION\n",
      "============================================================\n",
      "Using device: cuda\n",
      "\n",
      "Model Architecture:\n",
      "MultiHeadMLP(\n",
      "  (backbone): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (heads): ModuleList(\n",
      "    (0-4): 5 x Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Total parameters: 952,882\n",
      "\n",
      "============================================================\n",
      "PHASE 1: SEQUENTIAL TRAINING ON ALL TASKS\n",
      "============================================================\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 0\n",
      "Classes: [0, 1]\n",
      "────────────────────────────────────────\n",
      "Training task 0...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 26/26 [00:01<00:00, 22.82it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7000\n",
      "100%|██████████| 26/26 [00:00<00:00, 27.09it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9919\n",
      "100%|██████████| 26/26 [00:00<00:00, 26.52it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9945\n",
      "100%|██████████| 26/26 [00:00<00:00, 27.29it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9961\n",
      "100%|██████████| 26/26 [00:00<00:00, 27.32it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9964\n",
      "100%|██████████| 26/26 [00:00<00:00, 28.49it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9965\n",
      "100%|██████████| 26/26 [00:00<00:00, 27.02it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9966\n",
      "100%|██████████| 26/26 [00:01<00:00, 25.96it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9967\n",
      "100%|██████████| 26/26 [00:01<00:00, 22.75it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9967\n",
      "100%|██████████| 26/26 [00:00<00:00, 26.77it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9968\n",
      "-- >> End of training phase << --\n",
      "Task 0 training completed!\n",
      "Computing Fisher Information for task 0...\n",
      "Computing Fisher Information for task 0 with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 0% important weights...\n",
      "Saved 1 important weights to important_weights_task_0.pt\n",
      "Task 0 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 1\n",
      "Classes: [2, 3]\n",
      "────────────────────────────────────────\n",
      "Training task 1...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.93it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5612\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.78it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8877\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.72it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9196\n",
      "100%|██████████| 25/25 [00:00<00:00, 25.75it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9366\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.55it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9437\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.05it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9496\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.95it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9545\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.30it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9581\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.65it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9613\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.48it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9638\n",
      "-- >> End of training phase << --\n",
      "Task 1 training completed!\n",
      "Computing Fisher Information for task 1...\n",
      "Computing Fisher Information for task 1 with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 0% important weights...\n",
      "Saved 1 important weights to important_weights_task_1.pt\n",
      "Task 1 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 2\n",
      "Classes: [4, 5]\n",
      "────────────────────────────────────────\n",
      "Training task 2...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 23/23 [00:00<00:00, 27.58it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5754\n",
      "100%|██████████| 23/23 [00:00<00:00, 26.29it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8124\n",
      "100%|██████████| 23/23 [00:00<00:00, 28.83it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8721\n",
      "100%|██████████| 23/23 [00:00<00:00, 27.75it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9129\n",
      "100%|██████████| 23/23 [00:00<00:00, 27.95it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9379\n",
      "100%|██████████| 23/23 [00:00<00:00, 27.04it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9543\n",
      "100%|██████████| 23/23 [00:00<00:00, 23.31it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9633\n",
      "100%|██████████| 23/23 [00:00<00:00, 26.95it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9689\n",
      "100%|██████████| 23/23 [00:00<00:00, 28.64it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9737\n",
      "100%|██████████| 23/23 [00:00<00:00, 29.01it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9770\n",
      "-- >> End of training phase << --\n",
      "Task 2 training completed!\n",
      "Computing Fisher Information for task 2...\n",
      "Computing Fisher Information for task 2 with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 0% important weights...\n",
      "Saved 1 important weights to important_weights_task_2.pt\n",
      "Task 2 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 3\n",
      "Classes: [6, 7]\n",
      "────────────────────────────────────────\n",
      "Training task 3...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.14it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5765\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.48it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9347\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.62it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9807\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.04it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9916\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.09it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9943\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.21it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9954\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.53it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9960\n",
      "100%|██████████| 25/25 [00:00<00:00, 26.85it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9965\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.21it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9970\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.87it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9972\n",
      "-- >> End of training phase << --\n",
      "Task 3 training completed!\n",
      "Computing Fisher Information for task 3...\n",
      "Computing Fisher Information for task 3 with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 0% important weights...\n",
      "Saved 1 important weights to important_weights_task_3.pt\n",
      "Task 3 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 4\n",
      "Classes: [8, 9]\n",
      "────────────────────────────────────────\n",
      "Training task 4...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 24/24 [00:00<00:00, 27.10it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7115\n",
      "100%|██████████| 24/24 [00:00<00:00, 26.50it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9314\n",
      "100%|██████████| 24/24 [00:00<00:00, 26.75it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9459\n",
      "100%|██████████| 24/24 [00:01<00:00, 22.16it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9540\n",
      "100%|██████████| 24/24 [00:00<00:00, 27.09it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9587\n",
      "100%|██████████| 24/24 [00:00<00:00, 27.17it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9628\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.15it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9658\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.02it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9681\n",
      "100%|██████████| 24/24 [00:00<00:00, 27.79it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9710\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.55it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9720\n",
      "-- >> End of training phase << --\n",
      "Task 4 training completed!\n",
      "Computing Fisher Information for task 4...\n",
      "Computing Fisher Information for task 4 with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 0% important weights...\n",
      "Saved 1 important weights to important_weights_task_4.pt\n",
      "Task 4 completed and weights saved!\n",
      "\n",
      "============================================================\n",
      "PHASE 2: TASK-SPECIFIC INFERENCE WITH IMPORTANT WEIGHTS\n",
      "============================================================\n",
      "\n",
      "Evaluating all tasks with their respective important weights...\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 0\n",
      "──────────────────────────────\n",
      "Task 0 Accuracy: 99.62%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 1\n",
      "──────────────────────────────\n",
      "Task 1 Accuracy: 94.17%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 2\n",
      "──────────────────────────────\n",
      "Task 2 Accuracy: 98.51%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 3\n",
      "──────────────────────────────\n",
      "Task 3 Accuracy: 98.59%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 4\n",
      "──────────────────────────────\n",
      "Task 4 Accuracy: 96.57%\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "\n",
      "Final Test Accuracies:\n",
      "------------------------------\n",
      "Task 0: 99.62%\n",
      "Task 1: 94.17%\n",
      "Task 2: 98.51%\n",
      "Task 3: 98.59%\n",
      "Task 4: 96.57%\n",
      "------------------------------\n",
      "Average Accuracy: 97.49%\n",
      "\n",
      "Results saved to 'final_results.pt'\n",
      "Final model saved to 'final_multihead_model.pth'\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT COMPLETED!\n",
      "============================================================\n",
      "\n",
      "Experiment finished with average accuracy: 97.49%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "from avalanche.training import Naive\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.logging import InteractiveLogger\n",
    "\n",
    "from helper import (\n",
    "    MultiHeadMLP, \n",
    "    compute_empirical_fisher_information,\n",
    "    save_important_weights,\n",
    "    evaluate_task_with_specific_weights,\n",
    "    create_split_mnist_benchmark\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Setup\n",
    "    print(\"=\"*60)\n",
    "    print(\"TASK INCREMENTAL CONTINUAL LEARNING WITH FISHER INFORMATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create benchmark\n",
    "    benchmark = create_split_mnist_benchmark()\n",
    "    \n",
    "    # Create multi-head model  \n",
    "    model = MultiHeadMLP(\n",
    "        input_size=784,\n",
    "        hidden_size=512, \n",
    "        #num_classes_per_task=2,\n",
    "        num_tasks=5\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Storage for important weights paths\n",
    "    important_weights_paths = {}\n",
    "    \n",
    "    # Setup basic logger for training\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PHASE 1: SEQUENTIAL TRAINING ON ALL TASKS\")  \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training phase - train on each task sequentially\n",
    "    for task_id, experience in enumerate(benchmark.train_stream):\n",
    "        print(f\"\\n{'─'*40}\")\n",
    "        print(f\"Training on Task {task_id}\")\n",
    "        print(f\"Classes: {experience.classes_in_this_experience}\")\n",
    "        print(f\"{'─'*40}\")\n",
    "        \n",
    "        # Setup evaluation plugin for this task\n",
    "        eval_plugin = EvaluationPlugin(\n",
    "            accuracy_metrics(epoch=True, experience=True),\n",
    "            loggers=[interactive_logger]\n",
    "        )\n",
    "        \n",
    "        # Create strategy for this specific task\n",
    "        cl_strategy = Naive(\n",
    "            model,\n",
    "            SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "            CrossEntropyLoss(),\n",
    "            train_mb_size=500,\n",
    "            train_epochs=10,  # Increased epochs for better learning\n",
    "            eval_mb_size=100,\n",
    "            device=device,\n",
    "            evaluator=eval_plugin\n",
    "        )\n",
    "        \n",
    "        # Override forward method to use specific task head\n",
    "        def task_specific_forward(self, x):\n",
    "            return self.model(x, task_id=task_id)\n",
    "        \n",
    "        # Monkey patch the forward method (hack for avalanche)\n",
    "        original_forward = cl_strategy.model.forward\n",
    "        cl_strategy.model.forward = lambda x: original_forward(x, task_id=task_id)\n",
    "        \n",
    "        # Train on current task\n",
    "        print(f\"Training task {task_id}...\")\n",
    "        cl_strategy.train(experience)\n",
    "        \n",
    "        # Restore original forward method\n",
    "        cl_strategy.model.forward = original_forward\n",
    "        \n",
    "        print(f\"Task {task_id} training completed!\")\n",
    "        \n",
    "        # Compute Fisher Information for this task\n",
    "        print(f\"Computing Fisher Information for task {task_id}...\")\n",
    "        fisher_dict = compute_empirical_fisher_information(\n",
    "            model=model,\n",
    "            dataset=experience.dataset, \n",
    "            device=device,\n",
    "            num_samples=200,\n",
    "            task_id=task_id\n",
    "        )\n",
    "        \n",
    "        # Save important weights for this task\n",
    "        save_path = f\"important_weights_task_{task_id}.pt\"\n",
    "        save_important_weights(\n",
    "            model=model,\n",
    "            fisher_dict=fisher_dict,\n",
    "            top_n_percent=0,\n",
    "            save_path=save_path\n",
    "        )\n",
    "        important_weights_paths[task_id] = save_path\n",
    "        \n",
    "        print(f\"Task {task_id} completed and weights saved!\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PHASE 2: TASK-SPECIFIC INFERENCE WITH IMPORTANT WEIGHTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Evaluation phase - test each task with its specific important weights\n",
    "    final_accuracies = {}\n",
    "    \n",
    "    print(f\"\\nEvaluating all tasks with their respective important weights...\")\n",
    "    \n",
    "    for task_id in range(5):\n",
    "        print(f\"\\n{'─'*30}\")\n",
    "        print(f\"Evaluating Task {task_id}\")\n",
    "        print(f\"{'─'*30}\")\n",
    "        \n",
    "        # Get test experience for this task\n",
    "        test_experience = benchmark.test_stream[task_id]\n",
    "        \n",
    "        # Evaluate with task-specific important weights\n",
    "        accuracy = evaluate_task_with_specific_weights(\n",
    "            model=model,\n",
    "            test_experience=test_experience,\n",
    "            task_id=task_id,\n",
    "            important_weights_path=important_weights_paths[task_id],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        final_accuracies[f\"Task_{task_id}\"] = accuracy\n",
    "        print(f\"Task {task_id} Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Print final results summary\n",
    "    print(f\"\\nFinal Test Accuracies:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    total_accuracy = 0\n",
    "    for task_id in range(5):\n",
    "        acc = final_accuracies[f\"Task_{task_id}\"]\n",
    "        print(f\"Task {task_id}: {acc:.2f}%\")\n",
    "        total_accuracy += acc\n",
    "    \n",
    "    average_accuracy = total_accuracy / 5\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Average Accuracy: {average_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save final results\n",
    "    results_dict = {\n",
    "        'final_accuracies': final_accuracies,\n",
    "        'average_accuracy': average_accuracy,\n",
    "        'method': 'Task-Specific Important Weights'\n",
    "    }\n",
    "    \n",
    "    torch.save(results_dict, \"final_results.pt\")\n",
    "    print(f\"\\nResults saved to 'final_results.pt'\")\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), \"final_multihead_model.pth\") \n",
    "    print(f\"Final model saved to 'final_multihead_model.pth'\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"EXPERIMENT COMPLETED!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()\n",
    "    print(f\"\\nExperiment finished with average accuracy: {results['average_accuracy']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e61a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TASK INCREMENTAL CONTINUAL LEARNING WITH FISHER INFORMATION\n",
      "Using Simple MLP (No Multi-Head)\n",
      "============================================================\n",
      "Using device: cuda\n",
      "\n",
      "Model Architecture:\n",
      "SimpleMLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Total parameters: 932,362\n",
      "\n",
      "============================================================\n",
      "PHASE 1: SEQUENTIAL TRAINING ON ALL TASKS\n",
      "============================================================\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 0\n",
      "Classes: [0, 1]\n",
      "Dataset size: 12665\n",
      "────────────────────────────────────────\n",
      "Training task 0...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 26/26 [00:01<00:00, 23.83it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5823\n",
      "100%|██████████| 26/26 [00:00<00:00, 27.44it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9911\n",
      "100%|██████████| 26/26 [00:00<00:00, 28.79it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9941\n",
      "-- >> End of training phase << --\n",
      "Task 0 training completed!\n",
      "Computing Fisher Information for task 0...\n",
      "Computing Fisher Information with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 10.0% important weights...\n",
      "Saved 93,237 important weights to important_weights_task_0.pt\n",
      "Task 0 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 1\n",
      "Classes: [2, 3]\n",
      "Dataset size: 12089\n",
      "────────────────────────────────────────\n",
      "Training task 1...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.70it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1012\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.63it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8297\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.92it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9059\n",
      "-- >> End of training phase << --\n",
      "Task 1 training completed!\n",
      "Computing Fisher Information for task 1...\n",
      "Computing Fisher Information with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 10.0% important weights...\n",
      "Saved 93,237 important weights to important_weights_task_1.pt\n",
      "Task 1 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 2\n",
      "Classes: [4, 5]\n",
      "Dataset size: 11263\n",
      "────────────────────────────────────────\n",
      "Training task 2...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 23/23 [00:00<00:00, 28.27it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 23/23 [00:00<00:00, 28.04it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3398\n",
      "100%|██████████| 23/23 [00:00<00:00, 28.80it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6584\n",
      "-- >> End of training phase << --\n",
      "Task 2 training completed!\n",
      "Computing Fisher Information for task 2...\n",
      "Computing Fisher Information with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 10.0% important weights...\n",
      "Saved 93,237 important weights to important_weights_task_2.pt\n",
      "Task 2 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 3\n",
      "Classes: [6, 7]\n",
      "Dataset size: 12183\n",
      "────────────────────────────────────────\n",
      "Training task 3...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:01<00:00, 23.12it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.57it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1441\n",
      "100%|██████████| 25/25 [00:00<00:00, 28.78it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9799\n",
      "-- >> End of training phase << --\n",
      "Task 3 training completed!\n",
      "Computing Fisher Information for task 3...\n",
      "Computing Fisher Information with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 10.0% important weights...\n",
      "Saved 93,237 important weights to important_weights_task_3.pt\n",
      "Task 3 completed and weights saved!\n",
      "\n",
      "────────────────────────────────────────\n",
      "Training on Task 4\n",
      "Classes: [8, 9]\n",
      "Dataset size: 11800\n",
      "────────────────────────────────────────\n",
      "Training task 4...\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 24/24 [00:00<00:00, 27.45it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0000\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.75it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1056\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.08it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.6669\n",
      "-- >> End of training phase << --\n",
      "Task 4 training completed!\n",
      "Computing Fisher Information for task 4...\n",
      "Computing Fisher Information with 200 samples...\n",
      "  Processed 50 samples...\n",
      "  Processed 100 samples...\n",
      "  Processed 150 samples...\n",
      "  Processed 200 samples...\n",
      "Fisher Information computed for 200 samples!\n",
      "Saving top 10.0% important weights...\n",
      "Saved 93,237 important weights to important_weights_task_4.pt\n",
      "Task 4 completed and weights saved!\n",
      "\n",
      "============================================================\n",
      "PHASE 2: TASK-SPECIFIC INFERENCE WITH IMPORTANT WEIGHTS\n",
      "============================================================\n",
      "\n",
      "Evaluating all tasks with their respective important weights...\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 0\n",
      "──────────────────────────────\n",
      "Task 0 Accuracy: 89.74%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 1\n",
      "──────────────────────────────\n",
      "Task 1 Accuracy: 73.56%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 2\n",
      "──────────────────────────────\n",
      "Task 2 Accuracy: 90.82%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 3\n",
      "──────────────────────────────\n",
      "Task 3 Accuracy: 97.68%\n",
      "\n",
      "──────────────────────────────\n",
      "Evaluating Task 4\n",
      "──────────────────────────────\n",
      "Task 4 Accuracy: 63.59%\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS\n",
      "============================================================\n",
      "\n",
      "Final Test Accuracies:\n",
      "------------------------------\n",
      "Task 0: 89.74%\n",
      "Task 1: 73.56%\n",
      "Task 2: 90.82%\n",
      "Task 3: 97.68%\n",
      "Task 4: 63.59%\n",
      "------------------------------\n",
      "Average Accuracy: 83.08%\n",
      "\n",
      "========================================\n",
      "BASELINE: EVALUATION WITHOUT WEIGHT RESTORATION\n",
      "========================================\n",
      "Task 0 Baseline Accuracy: 0.00%\n",
      "Task 1 Baseline Accuracy: 0.00%\n",
      "Task 2 Baseline Accuracy: 0.00%\n",
      "Task 3 Baseline Accuracy: 0.00%\n",
      "Task 4 Baseline Accuracy: 63.59%\n",
      "Baseline Average Accuracy: 12.72%\n",
      "\n",
      "========================================\n",
      "COMPARISON\n",
      "========================================\n",
      "With Fisher Weight Restoration: 83.08%\n",
      "Without Weight Restoration:     12.72%\n",
      "Improvement: 70.36%\n",
      "\n",
      "Results saved to 'final_results_simple_mlp.pt'\n",
      "Final model saved to 'final_simple_mlp_model.pth'\n",
      "\n",
      "============================================================\n",
      "EXPERIMENT COMPLETED!\n",
      "============================================================\n",
      "\n",
      "Experiment finished:\n",
      "  Fisher Method: 83.08%\n",
      "  Baseline:      12.72%\n",
      "  Improvement:   70.36%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "from avalanche.training import Naive\n",
    "from avalanche.evaluation.metrics import accuracy_metrics\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.logging import InteractiveLogger\n",
    "\n",
    "from helper_simple import (\n",
    "    SimpleMLP, \n",
    "    compute_empirical_fisher_information,\n",
    "    save_important_weights,\n",
    "    evaluate_task_with_specific_weights,\n",
    "    create_split_mnist_benchmark\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Setup\n",
    "    print(\"=\"*60)\n",
    "    print(\"TASK INCREMENTAL CONTINUAL LEARNING WITH FISHER INFORMATION\")\n",
    "    print(\"Using Simple MLP (No Multi-Head)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create benchmark\n",
    "    benchmark = create_split_mnist_benchmark()\n",
    "    \n",
    "    # Create simple MLP model  \n",
    "    model = SimpleMLP(\n",
    "        input_size=784,\n",
    "        hidden_size=512, \n",
    "        num_classes=10\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"\\nModel Architecture:\")\n",
    "    print(model)\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Storage for important weights paths\n",
    "    important_weights_paths = {}\n",
    "    \n",
    "    # Setup basic logger for training\n",
    "    interactive_logger = InteractiveLogger()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PHASE 1: SEQUENTIAL TRAINING ON ALL TASKS\")  \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training phase - train on each task sequentially\n",
    "    for task_id, experience in enumerate(benchmark.train_stream):\n",
    "        print(f\"\\n{'─'*40}\")\n",
    "        print(f\"Training on Task {task_id}\")\n",
    "        print(f\"Classes: {experience.classes_in_this_experience}\")\n",
    "        print(f\"Dataset size: {len(experience.dataset)}\")\n",
    "        print(f\"{'─'*40}\")\n",
    "        \n",
    "        # Setup evaluation plugin for this task\n",
    "        eval_plugin = EvaluationPlugin(\n",
    "            accuracy_metrics(epoch=True, experience=True),\n",
    "            loggers=[interactive_logger]\n",
    "        )\n",
    "        \n",
    "        # Create strategy for this specific task\n",
    "        cl_strategy = Naive(\n",
    "            model,\n",
    "            SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "            CrossEntropyLoss(),\n",
    "            train_mb_size=500,\n",
    "            train_epochs=3,  # Reduced epochs to prevent overfitting\n",
    "            eval_mb_size=100,\n",
    "            device=device,\n",
    "            evaluator=eval_plugin\n",
    "        )\n",
    "        \n",
    "        # Train on current task (no need to modify forward method for simple MLP)\n",
    "        print(f\"Training task {task_id}...\")\n",
    "        cl_strategy.train(experience)\n",
    "        \n",
    "        print(f\"Task {task_id} training completed!\")\n",
    "        \n",
    "        # Compute Fisher Information for this task\n",
    "        print(f\"Computing Fisher Information for task {task_id}...\")\n",
    "        fisher_dict = compute_empirical_fisher_information(\n",
    "            model=model,\n",
    "            dataset=experience.dataset, \n",
    "            device=device,\n",
    "            num_samples=200\n",
    "        )\n",
    "        \n",
    "        # Save important weights for this task\n",
    "        save_path = f\"important_weights_task_{task_id}.pt\"\n",
    "        save_important_weights(\n",
    "            model=model,\n",
    "            fisher_dict=fisher_dict,\n",
    "            top_n_percent=10.0,  # Save top 10% important weights\n",
    "            save_path=save_path\n",
    "        )\n",
    "        important_weights_paths[task_id] = save_path\n",
    "        \n",
    "        print(f\"Task {task_id} completed and weights saved!\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PHASE 2: TASK-SPECIFIC INFERENCE WITH IMPORTANT WEIGHTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Evaluation phase - test each task with its specific important weights\n",
    "    final_accuracies = {}\n",
    "    \n",
    "    print(f\"\\nEvaluating all tasks with their respective important weights...\")\n",
    "    \n",
    "    for task_id in range(5):\n",
    "        print(f\"\\n{'─'*30}\")\n",
    "        print(f\"Evaluating Task {task_id}\")\n",
    "        print(f\"{'─'*30}\")\n",
    "        \n",
    "        # Get test experience for this task\n",
    "        test_experience = benchmark.test_stream[task_id]\n",
    "        \n",
    "        # Evaluate with task-specific important weights\n",
    "        accuracy = evaluate_task_with_specific_weights(\n",
    "            model=model,\n",
    "            test_experience=test_experience,\n",
    "            important_weights_path=important_weights_paths[task_id],\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        final_accuracies[f\"Task_{task_id}\"] = accuracy\n",
    "        print(f\"Task {task_id} Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Print final results summary\n",
    "    print(f\"\\nFinal Test Accuracies:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    total_accuracy = 0\n",
    "    for task_id in range(5):\n",
    "        acc = final_accuracies[f\"Task_{task_id}\"]\n",
    "        print(f\"Task {task_id}: {acc:.2f}%\")\n",
    "        total_accuracy += acc\n",
    "    \n",
    "    average_accuracy = total_accuracy / 5\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Average Accuracy: {average_accuracy:.2f}%\")\n",
    "    \n",
    "    # Additional analysis: Evaluate without weight restoration (baseline)\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"BASELINE: EVALUATION WITHOUT WEIGHT RESTORATION\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    baseline_accuracies = {}\n",
    "    for task_id in range(5):\n",
    "        test_experience = benchmark.test_stream[task_id]\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        from torch.utils.data import DataLoader\n",
    "        test_loader = DataLoader(test_experience.dataset, batch_size=100, shuffle=False, num_workers=0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                if isinstance(batch, (list, tuple)):\n",
    "                    inputs, targets = batch[0], batch[1]\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        baseline_accuracy = 100.0 * correct / total\n",
    "        baseline_accuracies[f\"Task_{task_id}\"] = baseline_accuracy\n",
    "        print(f\"Task {task_id} Baseline Accuracy: {baseline_accuracy:.2f}%\")\n",
    "    \n",
    "    baseline_avg = sum(baseline_accuracies.values()) / len(baseline_accuracies)\n",
    "    print(f\"Baseline Average Accuracy: {baseline_avg:.2f}%\")\n",
    "    \n",
    "    # Compare methods\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(\"COMPARISON\")\n",
    "    print(f\"{'='*40}\")\n",
    "    print(f\"With Fisher Weight Restoration: {average_accuracy:.2f}%\")\n",
    "    print(f\"Without Weight Restoration:     {baseline_avg:.2f}%\")\n",
    "    print(f\"Improvement: {average_accuracy - baseline_avg:.2f}%\")\n",
    "    \n",
    "    # Save final results\n",
    "    results_dict = {\n",
    "        'final_accuracies': final_accuracies,\n",
    "        'baseline_accuracies': baseline_accuracies,\n",
    "        'average_accuracy': average_accuracy,\n",
    "        'baseline_average': baseline_avg,\n",
    "        'improvement': average_accuracy - baseline_avg,\n",
    "        'method': 'Task-Specific Important Weights (Simple MLP)'\n",
    "    }\n",
    "    \n",
    "    torch.save(results_dict, \"final_results_simple_mlp.pt\")\n",
    "    print(f\"\\nResults saved to 'final_results_simple_mlp.pt'\")\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), \"final_simple_mlp_model.pth\") \n",
    "    print(f\"Final model saved to 'final_simple_mlp_model.pth'\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"EXPERIMENT COMPLETED!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()\n",
    "    print(f\"\\nExperiment finished:\")\n",
    "    print(f\"  Fisher Method: {results['average_accuracy']:.2f}%\")\n",
    "    print(f\"  Baseline:      {results['baseline_average']:.2f}%\")\n",
    "    print(f\"  Improvement:   {results['improvement']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be19de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "SimpleMLP(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Top1_Acc_Epoch/train_phase/train_stream/Task000</td><td>█▃▁▂▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000</td><td>█▃▂▂▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001</td><td>█▃▁▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002</td><td>█▃▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003</td><td>█▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004</td><td>▁</td></tr><tr><td>Top1_Acc_MB/train_phase/train_stream/Task000</td><td>▄▇████████▁▁▁▃▇▇▇▁▁▁▁▆▇▁▁▁▃▅▆▇▁▁▁▁▁▅▇▇▇▇</td></tr><tr><td>Top1_Acc_Stream/eval_phase/test_stream/Task000</td><td>█▆▃▁▁</td></tr><tr><td>TrainingExperience</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Top1_Acc_Epoch/train_phase/train_stream/Task000</td><td>0.32466</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000</td><td>0.52151</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001</td><td>0.06464</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002</td><td>0.00854</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003</td><td>0.6279</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004</td><td>0.941</td></tr><tr><td>Top1_Acc_MB/train_phase/train_stream/Task000</td><td>0.91333</td></tr><tr><td>Top1_Acc_Stream/eval_phase/test_stream/Task000</td><td>0.4364</td></tr><tr><td>TrainingExperience</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1</strong> at: <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/ilodmhuw' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/ilodmhuw</a><br> View project at: <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21</a><br>Synced 8 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_183454-ilodmhuw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ep22b035/Parameter_Replay/wandb/run-20251016_183547-t1nss4o0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/t1nss4o0' target=\"_blank\">run_1</a></strong> to <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/t1nss4o0' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/t1nss4o0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ep22b035/.local/lib/python3.13/site-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the Naive.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "Start of experience:  0\n",
      "Current Classes:  [0, 1]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 26/26 [00:00<00:00, 47.65it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8057\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing Fisher Information\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000017\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp0.pt'\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 62.17it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9967\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 64.53it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 60.25it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 57.19it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 69.26it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2108\n",
      "Param: features.0.weight, Fisher Info Mean: 0.000008\n",
      "Param: features.0.bias, Fisher Info Mean: 0.000010\n",
      "Param: classifier.weight, Fisher Info Mean: 0.000333\n",
      "Param: classifier.bias, Fisher Info Mean: 0.001647\n",
      "Start of experience:  1\n",
      "Current Classes:  [2, 3]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 27.41it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4517\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9213\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing Fisher Information\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000159\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp1.pt'\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 67.30it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1017\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 70.54it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9216\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 63.03it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 65.91it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 63.50it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2097\n",
      "Param: features.0.weight, Fisher Info Mean: 0.000067\n",
      "Param: features.0.bias, Fisher Info Mean: 0.000066\n",
      "Param: classifier.weight, Fisher Info Mean: 0.003660\n",
      "Param: classifier.bias, Fisher Info Mean: 0.018335\n",
      "Start of experience:  2\n",
      "Current Classes:  [4, 5]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 23/23 [00:00<00:00, 43.10it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3040\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8935\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing Fisher Information\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000230\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp2.pt'\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 70.15it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3452\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 71.54it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1949\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 65.51it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9285\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 73.76it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 64.77it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2868\n",
      "Param: features.0.weight, Fisher Info Mean: 0.000091\n",
      "Param: features.0.bias, Fisher Info Mean: 0.000101\n",
      "Param: classifier.weight, Fisher Info Mean: 0.003374\n",
      "Param: classifier.bias, Fisher Info Mean: 0.030729\n",
      "Start of experience:  3\n",
      "Current Classes:  [6, 7]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 45.62it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3213\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9836\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing Fisher Information\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000181\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp3.pt'\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 75.35it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3636\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 66.71it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0122\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 67.39it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1985\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 62.69it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9718\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 61.62it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3096\n",
      "Param: features.0.weight, Fisher Info Mean: 0.000081\n",
      "Param: features.0.bias, Fisher Info Mean: 0.000092\n",
      "Param: classifier.weight, Fisher Info Mean: 0.002627\n",
      "Param: classifier.bias, Fisher Info Mean: 0.027834\n",
      "Start of experience:  4\n",
      "Current Classes:  [8, 9]\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 24/24 [00:00<00:00, 44.50it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1550\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.7733\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "Computing Fisher Information\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000209\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp4.pt'\n",
      "Computing accuracy on the whole test set\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 65.73it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4156\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 64.15it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0122\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 66.09it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0438\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 65.76it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6546\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 73.44it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.8346\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3941\n",
      "Param: features.0.weight, Fisher Info Mean: 0.000108\n",
      "Param: features.0.bias, Fisher Info Mean: 0.000111\n",
      "Param: classifier.weight, Fisher Info Mean: 0.003945\n",
      "Param: classifier.bias, Fisher Info Mean: 0.060335\n",
      "Model saved as final_splitmnist_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics,\\\n",
    "    loss_metrics, timing_metrics, cpu_usage_metrics, StreamConfusionMatrix,\\\n",
    "    disk_usage_metrics, gpu_usage_metrics\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training import Naive\n",
    "from wandb_logger import WandBLogger\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch \n",
    "\n",
    "from fisher_info import compute_empirical_fisher_information,plot_fisher_information_detailed,plot_fisher_information_heatmap\n",
    "\n",
    "\n",
    "benchmark = SplitMNIST(n_experiences=5,return_task_id=False,seed=42,shuffle=False)   #creates the benchmark\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = SimpleMLP(num_classes=benchmark.n_classes).to(device)   #creates the model\n",
    "print(model)\n",
    "\n",
    "tb_logger = WandBLogger(project_name=\"avalanche_tut_!\", run_name=\"run_1\") #WandB logger\n",
    "text_logger = TextLogger(open('log.txt', 'a'))\n",
    "interactive_logger = InteractiveLogger()\n",
    "\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    #loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    #timing_metrics(epoch=True),\n",
    "    #cpu_usage_metrics(experience=True),\n",
    "    #forgetting_metrics(experience=True, stream=True),\n",
    "    #StreamConfusionMatrix(num_classes=benchmark.n_classes, save_image=False),\n",
    "    #disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=[interactive_logger, text_logger, tb_logger]\n",
    ")\n",
    "\n",
    "cl_strategy = Naive(\n",
    "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,device=device,\n",
    "    evaluator=eval_plugin)\n",
    "\n",
    "\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "fisher_dicts=[]\n",
    "weights_per_experience = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "    res = cl_strategy.train(experience, num_workers=4)\n",
    "    print('Training completed')\n",
    "\n",
    "\n",
    "    \n",
    "    print('Computing Fisher Information')\n",
    "    fisher_dict = compute_empirical_fisher_information(\n",
    "        model=model,\n",
    "        dataset=experience.dataset,\n",
    "        device=device,\n",
    "        num_samples=200  # Limit to 200 samples for testing\n",
    "    ) \n",
    "    fisher_dicts.append(fisher_dict)\n",
    "    #plot_fisher_information_detailed(fisher_dict,model=model,save_path=f'fisher_detailed_exp{experience.current_experience}.png')   \n",
    "    #print(fisher_dict)\n",
    "    weights_per_experience.append(save_top_n_percent_weights(model, fisher_dict, top_n_percent=10.0, save_path=f\"important_weights_exp{experience.current_experience}.pt\"))\n",
    "    \n",
    "    print('Computing accuracy on the whole test set')\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream, num_workers=4))\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in fisher_dict:\n",
    "            print(f\"Param: {name}, Fisher Info Mean: {fisher_dict[name].mean().item():.6f}\")\n",
    "        else :\n",
    "            print(f\"Param: {name} not found in Fisher Info dictionary.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"final_splitmnist_model.pth\")\n",
    "print(\"Model saved as final_splitmnist_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20307f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "# ----------------------------------\n",
    "# FUNCTION 1: SAVE IMPORTANT WEIGHTS\n",
    "# ----------------------------------\n",
    "def save_top_n_percent_weights(model, fisher_dict, top_n_percent, save_path=\"important_weights.pt\"):\n",
    "    \"\"\"\n",
    "    Identifies and saves the top N% of weights based on Fisher scores.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model.\n",
    "        fisher_dict (dict): A dictionary with layer names as keys and Fisher score tensors as values.\n",
    "        top_n_percent (float): The percentage of top weights to save (e.g., 20.0 for top 20%).\n",
    "        save_path (str): Path to save the resulting data.\n",
    "    \"\"\"\n",
    "    print(f\"--- Identifying and saving top {top_n_percent}% of weights ---\")\n",
    "    \n",
    "    # 1. Flatten all Fisher scores into a single tensor to find the global threshold\n",
    "    all_scores = torch.cat([f.view(-1) for f in fisher_dict.values()])\n",
    "    #print(all_scores)\n",
    "    # 2. Calculate the threshold value. For the top 20%, we need the 80th percentile.\n",
    "    threshold_quantile = 1.0 - (top_n_percent / 100.0)\n",
    "    threshold = torch.quantile(all_scores, threshold_quantile)\n",
    "    print(f\"Threshold for top {top_n_percent}% weights: {threshold:.6f}\")\n",
    "    important_weights_data = {}\n",
    "    total_important_weights = 0\n",
    "\n",
    "    # 3. Create masks and store the original values of the important weights\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            #print(name)\n",
    "            if name in fisher_dict:\n",
    "                #print(name)\n",
    "                # Create a binary mask: 1 where score > threshold, 0 otherwise\n",
    "                mask = fisher_dict[name] >= threshold\n",
    "                \n",
    "                # Use the mask to get the actual weight values from the model\n",
    "                important_values = param.data[mask]\n",
    "                \n",
    "                # Store both the mask and the values\n",
    "                important_weights_data[name] = {\n",
    "                    'mask': mask.cpu(),  # Move to CPU for saving\n",
    "                    'values': important_values.cpu()\n",
    "                }\n",
    "                total_important_weights += important_values.numel()\n",
    "\n",
    "    print(f\"Found {total_important_weights:,} important weights.\")\n",
    "    print(f\"Saving masks and values to '{save_path}'\")\n",
    "    torch.save(important_weights_data, save_path)\n",
    "    return important_weights_data\n",
    "\n",
    "\n",
    "# ------------------------------------\n",
    "# FUNCTION 2: RESTORE IMPORTANT WEIGHTS\n",
    "# ------------------------------------\n",
    "def restore_important_weights(model, load_path=\"important_weights.pt\"):\n",
    "    \"\"\"\n",
    "    Restores the saved important weights into a new model instance.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to restore weights into (e.g., after retraining).\n",
    "        load_path (str): Path to the saved important weights data.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: The model with important weights restored.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Restoring important weights from '{load_path}' ---\")\n",
    "    \n",
    "    # Load the saved masks and values\n",
    "    important_weights_data = torch.load(load_path)\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    restored_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in important_weights_data:\n",
    "                data = important_weights_data[name]\n",
    "                mask = data['mask'].to(device)\n",
    "                saved_values = data['values'].to(device)\n",
    "                \n",
    "                # Use the mask to overwrite values in the current model\n",
    "                param.data[mask] = saved_values\n",
    "                restored_count += saved_values.numel()\n",
    "                \n",
    "    print(f\"Restored {restored_count:,} weights into the model.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# EXAMPLE USAGE\n",
    "# ----------------------------------\n",
    "if __name__ == '__main__sjhfb':\n",
    "    \n",
    "    # 1. Create a dummy model and dummy Fisher scores\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(10, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 2)\n",
    "    )\n",
    "    # The Fisher dict has the same keys and tensor shapes as the model's state_dict\n",
    "    fisher_dict = {name: torch.rand_like(p) for name, p in model.named_parameters() if p.requires_grad}\n",
    "\n",
    "    # 2. Save the top 20% of weights from the original model\n",
    "    save_top_n_percent_weights(model, fisher_dict, top_n_percent=20.0)\n",
    "\n",
    "    # 3. Simulate retraining: create a new model instance with different weights\n",
    "    retrained_model = copy.deepcopy(model)\n",
    "    # Let's change all weights to prove the restoration works\n",
    "    with torch.no_grad():\n",
    "        for param in retrained_model.parameters():\n",
    "            param.data.fill_(999.0) # Fill with a placeholder value\n",
    "\n",
    "    # 4. Verify that a specific important weight has been changed\n",
    "    original_weight_value = model[0].weight[0, 0].item()\n",
    "    print(f\"\\nAn original important weight value (example): {original_weight_value:.4f}\")\n",
    "    print(f\"Same weight in 'retrained' model before restoration: {retrained_model[0].weight[0, 0].item():.4f}\")\n",
    "\n",
    "    # 5. Restore the saved important weights into the \"retrained\" model\n",
    "    restored_model = restore_important_weights(retrained_model)\n",
    "\n",
    "    # 6. Final verification\n",
    "    print(f\"Same weight in model AFTER restoration: {restored_model[0].weight[0, 0].item():.4f}\")\n",
    "\n",
    "    # Check that only the important weights were changed and others remain 999.0\n",
    "    important_data = torch.load(\"important_weights.pt\")\n",
    "    mask_for_first_layer = important_data['0.weight']['mask']\n",
    "    \n",
    "    # Find a location that was NOT important (where mask is False)\n",
    "    unimportant_indices = (mask_for_first_layer == False).nonzero()[0]\n",
    "    unimportant_val = restored_model[0].weight[unimportant_indices[0], unimportant_indices[1]].item()\n",
    "    print(f\"Value of an UNIMPORTANT weight after restoration: {unimportant_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19646b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000029\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp0.pt'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'features.0.weight': {'mask': tensor([[False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]),\n",
       "  'values': tensor([ 0.0137,  0.0003,  0.0323,  ..., -0.0181,  0.0329,  0.0316])},\n",
       " 'features.0.bias': {'mask': tensor([False, False, False, False, False,  True, False, False, False, False,\n",
       "          False,  True, False, False, False, False, False, False, False, False,\n",
       "          False,  True, False, False, False, False, False,  True, False,  True,\n",
       "          False, False, False, False, False, False, False,  True, False, False,\n",
       "           True,  True, False, False, False,  True, False, False, False, False,\n",
       "           True, False,  True, False, False, False, False, False, False, False,\n",
       "          False, False,  True,  True, False, False,  True, False, False, False,\n",
       "          False, False,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False,  True,  True, False, False,  True, False,  True,\n",
       "          False, False, False,  True, False, False,  True, False, False,  True,\n",
       "          False, False, False, False, False, False, False, False,  True, False,\n",
       "          False, False, False, False,  True, False, False,  True,  True, False,\n",
       "           True, False,  True, False, False,  True, False, False, False, False,\n",
       "          False, False, False, False, False, False, False,  True, False,  True,\n",
       "          False, False, False, False, False, False, False,  True,  True, False,\n",
       "          False, False, False, False, False,  True, False, False, False, False,\n",
       "           True,  True, False, False, False, False,  True, False, False, False,\n",
       "          False,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False,  True, False,  True, False,\n",
       "          False, False,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False,  True,  True, False,\n",
       "           True,  True, False, False, False, False, False, False, False,  True,\n",
       "          False, False, False, False, False, False, False, False, False,  True,\n",
       "          False,  True, False, False, False,  True, False, False, False, False,\n",
       "          False,  True, False,  True, False,  True, False, False, False,  True,\n",
       "          False,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False,  True,  True, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False,  True, False, False, False, False,  True, False,\n",
       "           True, False, False, False,  True, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False,  True, False, False,\n",
       "           True, False, False, False, False, False, False, False, False, False,\n",
       "          False,  True, False,  True, False, False, False, False, False, False,\n",
       "          False, False,  True,  True, False, False, False, False, False, False,\n",
       "          False, False, False, False,  True, False, False, False, False, False,\n",
       "          False,  True, False,  True, False,  True, False, False, False, False,\n",
       "           True, False, False, False, False,  True, False, False, False,  True,\n",
       "          False, False, False, False, False, False, False,  True, False, False,\n",
       "          False, False, False,  True, False, False, False, False, False, False,\n",
       "          False, False,  True, False, False, False, False, False,  True, False,\n",
       "          False, False, False, False,  True, False, False, False,  True, False,\n",
       "          False,  True,  True, False, False, False, False, False, False, False,\n",
       "          False, False, False,  True,  True,  True,  True, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False,  True, False,\n",
       "          False, False,  True, False, False,  True, False, False,  True, False,\n",
       "          False, False, False,  True, False, False,  True, False, False, False,\n",
       "          False, False, False, False,  True, False,  True,  True, False, False,\n",
       "          False, False,  True, False, False, False, False, False, False,  True,\n",
       "           True, False, False, False, False, False,  True, False, False, False,\n",
       "           True, False, False,  True,  True, False,  True, False, False, False,\n",
       "           True, False]),\n",
       "  'values': tensor([-3.3576e-02, -8.0484e-03, -4.4346e-03, -2.1241e-04,  2.0779e-02,\n",
       "           3.5103e-02, -3.4473e-02, -1.2585e-02,  2.1595e-02, -3.3729e-03,\n",
       "           2.2794e-02, -2.5388e-02, -9.5990e-03,  1.9303e-02,  2.1082e-02,\n",
       "           2.1269e-02, -1.5836e-02, -9.0396e-03,  1.1891e-02, -1.1056e-02,\n",
       "          -6.8205e-03,  2.2837e-02, -3.7600e-02, -2.8595e-02,  9.7131e-05,\n",
       "           2.5736e-02,  2.4569e-02,  1.0334e-02, -1.0120e-02, -2.3401e-03,\n",
       "          -3.6577e-02,  1.3318e-02,  2.6357e-03,  1.9076e-02,  6.9065e-03,\n",
       "          -2.6921e-02, -9.9972e-03, -2.6234e-02,  9.6881e-03,  7.8656e-03,\n",
       "          -1.9698e-02, -3.3651e-02,  1.6985e-03,  3.0297e-02, -2.8565e-02,\n",
       "          -1.5421e-02, -2.9641e-02,  2.1293e-02, -2.4275e-02, -2.2596e-03,\n",
       "           1.0639e-02, -9.6762e-03,  8.1699e-03,  1.0116e-02, -1.6452e-02,\n",
       "           3.4146e-02,  2.7383e-02,  3.0906e-04, -1.7868e-02, -3.3331e-02,\n",
       "          -1.9278e-02, -1.7054e-03, -1.1758e-02, -4.1942e-03,  1.7244e-04,\n",
       "           9.1441e-03,  1.9706e-03,  6.0395e-03,  1.7931e-02,  1.4876e-02,\n",
       "          -1.3691e-02, -9.2415e-03,  1.1237e-02, -4.1455e-03,  2.0166e-02,\n",
       "           3.3240e-02,  9.2949e-03,  5.3909e-03,  3.1483e-02, -2.9759e-04,\n",
       "           1.4734e-02, -1.5497e-02,  5.3431e-03,  1.4343e-02, -4.0676e-04,\n",
       "           1.6645e-02, -2.4954e-02,  1.9393e-02,  1.9762e-02,  2.6851e-02,\n",
       "           1.0433e-02,  1.8492e-02,  3.3653e-02, -4.1125e-03,  1.0623e-02,\n",
       "           2.0370e-02, -3.4177e-02, -2.1055e-02,  1.2215e-02, -2.1958e-02,\n",
       "          -3.2121e-02, -8.1293e-03, -1.5921e-02])},\n",
       " 'classifier.weight': {'mask': tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          ...,\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False],\n",
       "          [False, False, False,  ..., False, False, False]]),\n",
       "  'values': tensor([-0.0302, -0.0176,  0.0078,  ...,  0.0274,  0.0330, -0.0569])},\n",
       " 'classifier.bias': {'mask': tensor([True, True, True, True, True, True, True, True, True, True]),\n",
       "  'values': tensor([-0.0762, -0.0007, -0.0333,  0.0008, -0.0300,  0.0012, -0.0018,  0.0013,\n",
       "           0.0375,  0.0106])}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_top_n_percent_weights(model, fisher_dicts[0], top_n_percent=10.0, save_path=\"important_weights_exp0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55124384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "SimpleMLP(\n",
      "  (features): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Top1_Acc_Epoch/train_phase/train_stream/Task000</td><td>█▃▁▂▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000</td><td>█▄▄▁▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001</td><td>█▄▁▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002</td><td>█▂▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003</td><td>█▁</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004</td><td>▁</td></tr><tr><td>Top1_Acc_MB/train_phase/train_stream/Task000</td><td>▂▅▆▇██████▁▁▃▅▆▇▇▁▁▁▁▁▁▁▁▇▇▁▁▁▁▇▇█▁▃▅▆▇▇</td></tr><tr><td>Top1_Acc_Stream/eval_phase/test_stream/Task000</td><td>█▆▄▁▁</td></tr><tr><td>TrainingExperience</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Top1_Acc_Epoch/train_phase/train_stream/Task000</td><td>0.34822</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000</td><td>0.57825</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001</td><td>0.0573</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002</td><td>0.01067</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003</td><td>0.429</td></tr><tr><td>Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004</td><td>0.94453</td></tr><tr><td>Top1_Acc_MB/train_phase/train_stream/Task000</td><td>0.92667</td></tr><tr><td>Top1_Acc_Stream/eval_phase/test_stream/Task000</td><td>0.4085</td></tr><tr><td>TrainingExperience</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_1</strong> at: <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/yirbp68p' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/yirbp68p</a><br> View project at: <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21</a><br>Synced 8 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251016_183738-yirbp68p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ep22b035/Parameter_Replay/wandb/run-20251016_184924-7ajpimm4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/7ajpimm4' target=\"_blank\">run_1</a></strong> to <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/7ajpimm4' target=\"_blank\">https://wandb.ai/ep22b035-iit-madras-foundation/avalanche_tut_%21/runs/7ajpimm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ep22b035/.local/lib/python3.13/site-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the Naive.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment...\n",
      "\n",
      "============================================================\n",
      "Start of experience: 0\n",
      "Current Classes: [0, 1]\n",
      "============================================================\n",
      "\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 26/26 [00:00<00:00, 48.76it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8707\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "100%|██████████| 26/26 [00:00<00:00, 43.63it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9939\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "100%|██████████| 26/26 [00:00<00:00, 46.21it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9957\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 26/26 [00:00<00:00, 46.21it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9958\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "100%|██████████| 26/26 [00:00<00:00, 50.53it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9965\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "100%|██████████| 26/26 [00:00<00:00, 45.93it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9968\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 26/26 [00:00<00:00, 33.35it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9971\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "100%|██████████| 26/26 [00:00<00:00, 45.94it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9968\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 26/26 [00:00<00:00, 47.59it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9969\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "100%|██████████| 26/26 [00:00<00:00, 47.27it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9974\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9939\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "\n",
      "Computing Fisher Information for experience 0...\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "\n",
      "Fisher Information Statistics for Experience 0:\n",
      "  features.0.weight: Mean=0.000000, Max=0.000006\n",
      "  features.0.bias: Mean=0.000000, Max=0.000001\n",
      "  classifier.weight: Mean=0.000002, Max=0.000102\n",
      "  classifier.bias: Mean=0.000008, Max=0.000045\n",
      "\n",
      "Saving top 10% important weights for experience 0...\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000000\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp0.pt'\n",
      "\n",
      "============================================================\n",
      "Evaluating on all test experiences (0 to 0)...\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Evaluating on Test Experience 0 ---\n",
      "Restoring important weights from experience 0...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp0.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 70.42it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9986\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9986\n",
      "Results on test experience 0: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9939393939393939, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9973943939992104, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.9985815602836879, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.9985815602836879}\n",
      "Completed evaluation on test experience 0\n",
      "\n",
      "Computing accuracy on the whole test set (experiences 0-0)...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 79.01it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9986\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9986\n",
      "\n",
      "============================================================\n",
      "Start of experience: 1\n",
      "Current Classes: [2, 3]\n",
      "============================================================\n",
      "\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 53.02it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4422\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9326\n",
      "100%|██████████| 25/25 [00:00<00:00, 46.31it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9262\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9101\n",
      "100%|██████████| 25/25 [00:00<00:00, 48.54it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9395\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9551\n",
      "100%|██████████| 25/25 [00:00<00:00, 48.14it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9488\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9888\n",
      "100%|██████████| 25/25 [00:00<00:00, 34.94it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9542\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9775\n",
      "100%|██████████| 25/25 [00:00<00:00, 56.03it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9588\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9551\n",
      "100%|██████████| 25/25 [00:00<00:00, 46.76it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9594\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9438\n",
      "100%|██████████| 25/25 [00:00<00:00, 48.74it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9615\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9438\n",
      "100%|██████████| 25/25 [00:00<00:00, 49.21it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9619\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9775\n",
      "100%|██████████| 25/25 [00:00<00:00, 50.61it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9630\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9775\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "\n",
      "Computing Fisher Information for experience 1...\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "\n",
      "Fisher Information Statistics for Experience 1:\n",
      "  features.0.weight: Mean=0.000032, Max=0.003799\n",
      "  features.0.bias: Mean=0.000030, Max=0.000575\n",
      "  classifier.weight: Mean=0.000907, Max=0.093623\n",
      "  classifier.bias: Mean=0.002785, Max=0.014006\n",
      "\n",
      "Saving top 10% important weights for experience 1...\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000055\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp1.pt'\n",
      "\n",
      "============================================================\n",
      "Evaluating on all test experiences (0 to 1)...\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Evaluating on Test Experience 0 ---\n",
      "Restoring important weights from experience 0...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp0.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 78.72it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9418\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9418\n",
      "Results on test experience 0: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9775280898876404, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9630242369095873, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.9418439716312057, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.9418439716312057}\n",
      "Completed evaluation on test experience 0\n",
      "\n",
      "--- Evaluating on Test Experience 1 ---\n",
      "Restoring important weights from experience 1...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp1.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 69.19it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9706\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9706\n",
      "Results on test experience 1: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9775280898876404, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9630242369095873, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.9418439716312057, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.970617042115573, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.970617042115573}\n",
      "Completed evaluation on test experience 1\n",
      "\n",
      "Computing accuracy on the whole test set (experiences 0-1)...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 84.49it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7787\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 77.83it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9706\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.8730\n",
      "\n",
      "============================================================\n",
      "Start of experience: 2\n",
      "Current Classes: [4, 5]\n",
      "============================================================\n",
      "\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 23/23 [00:00<00:00, 46.59it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2670\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8593\n",
      "100%|██████████| 23/23 [00:00<00:00, 44.03it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9203\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9468\n",
      "100%|██████████| 23/23 [00:00<00:00, 30.08it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9460\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9468\n",
      "100%|██████████| 23/23 [00:00<00:00, 43.84it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9586\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9506\n",
      "100%|██████████| 23/23 [00:00<00:00, 43.65it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9656\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9772\n",
      "100%|██████████| 23/23 [00:00<00:00, 43.90it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9703\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9772\n",
      "100%|██████████| 23/23 [00:00<00:00, 41.52it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9724\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9620\n",
      "100%|██████████| 23/23 [00:00<00:00, 42.85it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9766\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9772\n",
      "100%|██████████| 23/23 [00:00<00:00, 46.17it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9785\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9696\n",
      "100%|██████████| 23/23 [00:00<00:00, 41.50it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9808\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9924\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "\n",
      "Computing Fisher Information for experience 2...\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "\n",
      "Fisher Information Statistics for Experience 2:\n",
      "  features.0.weight: Mean=0.000036, Max=0.003565\n",
      "  features.0.bias: Mean=0.000040, Max=0.000697\n",
      "  classifier.weight: Mean=0.000953, Max=0.101297\n",
      "  classifier.bias: Mean=0.003690, Max=0.018616\n",
      "\n",
      "Saving top 10% important weights for experience 2...\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000066\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp2.pt'\n",
      "\n",
      "============================================================\n",
      "Evaluating on all test experiences (0 to 2)...\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Evaluating on Test Experience 0 ---\n",
      "Restoring important weights from experience 0...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp0.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 74.24it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4227\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4227\n",
      "Results on test experience 0: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9923954372623575, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9808221610583326, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.4226950354609929, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.4226950354609929, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.970617042115573}\n",
      "Completed evaluation on test experience 0\n",
      "\n",
      "--- Evaluating on Test Experience 1 ---\n",
      "Restoring important weights from experience 1...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp1.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 72.03it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3369\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3369\n",
      "Results on test experience 1: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9923954372623575, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9808221610583326, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.4226950354609929, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.33692458374143, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.33692458374143}\n",
      "Completed evaluation on test experience 1\n",
      "\n",
      "--- Evaluating on Test Experience 2 ---\n",
      "Restoring important weights from experience 2...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp2.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 63.65it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9872\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9872\n",
      "Results on test experience 2: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9923954372623575, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9808221610583326, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.4226950354609929, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.9871931696905016, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.33692458374143, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.9871931696905016}\n",
      "Completed evaluation on test experience 2\n",
      "\n",
      "Computing accuracy on the whole test set (experiences 0-2)...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 71.69it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3097\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 70.90it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2262\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 65.74it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9872\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4920\n",
      "\n",
      "============================================================\n",
      "Start of experience: 3\n",
      "Current Classes: [6, 7]\n",
      "============================================================\n",
      "\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 25/25 [00:00<00:00, 47.59it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3467\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9727\n",
      "100%|██████████| 25/25 [00:00<00:00, 32.21it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9845\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9836\n",
      "100%|██████████| 25/25 [00:00<00:00, 46.10it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9910\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "100%|██████████| 25/25 [00:00<00:00, 50.13it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9911\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9836\n",
      "100%|██████████| 25/25 [00:00<00:00, 44.85it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9924\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9945\n",
      "100%|██████████| 25/25 [00:00<00:00, 42.71it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9934\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9945\n",
      "100%|██████████| 25/25 [00:00<00:00, 44.66it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9943\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9891\n",
      "100%|██████████| 25/25 [00:00<00:00, 44.98it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9938\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9891\n",
      "100%|██████████| 25/25 [00:00<00:00, 50.29it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9950\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9945\n",
      "100%|██████████| 25/25 [00:00<00:00, 31.54it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9946\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "\n",
      "Computing Fisher Information for experience 3...\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "\n",
      "Fisher Information Statistics for Experience 3:\n",
      "  features.0.weight: Mean=0.000004, Max=0.000634\n",
      "  features.0.bias: Mean=0.000005, Max=0.000090\n",
      "  classifier.weight: Mean=0.000072, Max=0.007610\n",
      "  classifier.bias: Mean=0.000479, Max=0.002852\n",
      "\n",
      "Saving top 10% important weights for experience 3...\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000007\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp3.pt'\n",
      "\n",
      "============================================================\n",
      "Evaluating on all test experiences (0 to 3)...\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Evaluating on Test Experience 0 ---\n",
      "Restoring important weights from experience 0...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp0.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 75.93it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3400\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3400\n",
      "Results on test experience 0: {'Top1_Acc_MB/train_phase/train_stream/Task000': 1.0, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9945826151194287, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.3399527186761229, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.3399527186761229, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.22624877571008814, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.9871931696905016}\n",
      "Completed evaluation on test experience 0\n",
      "\n",
      "--- Evaluating on Test Experience 1 ---\n",
      "Restoring important weights from experience 1...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp1.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 70.51it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2307\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2307\n",
      "Results on test experience 1: {'Top1_Acc_MB/train_phase/train_stream/Task000': 1.0, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9945826151194287, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.3399527186761229, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.23065621939275222, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.23065621939275222, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.9871931696905016}\n",
      "Completed evaluation on test experience 1\n",
      "\n",
      "--- Evaluating on Test Experience 2 ---\n",
      "Restoring important weights from experience 2...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp2.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 65.57it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.8394\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.8394\n",
      "Results on test experience 2: {'Top1_Acc_MB/train_phase/train_stream/Task000': 1.0, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9945826151194287, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.3399527186761229, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.8393810032017076, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.23065621939275222, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.8393810032017076}\n",
      "Completed evaluation on test experience 2\n",
      "\n",
      "--- Evaluating on Test Experience 3 ---\n",
      "Restoring important weights from experience 3...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp3.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 73.01it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9884\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9884\n",
      "Results on test experience 3: {'Top1_Acc_MB/train_phase/train_stream/Task000': 1.0, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.9945826151194287, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.3399527186761229, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.9884189325276939, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.23065621939275222, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.8393810032017076, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.9884189325276939}\n",
      "Completed evaluation on test experience 3\n",
      "\n",
      "Computing accuracy on the whole test set (experiences 0-3)...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 77.64it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0061\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 67.79it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0020\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 70.98it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3212\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 74.38it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9884\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3221\n",
      "\n",
      "============================================================\n",
      "Start of experience: 4\n",
      "Current Classes: [8, 9]\n",
      "============================================================\n",
      "\n",
      "-- >> Start of training phase << --\n",
      "100%|██████████| 24/24 [00:00<00:00, 49.29it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2911\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9333\n",
      "100%|██████████| 24/24 [00:00<00:00, 43.20it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9267\n",
      "100%|██████████| 24/24 [00:00<00:00, 55.86it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9387\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9300\n",
      "100%|██████████| 24/24 [00:00<00:00, 47.63it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9496\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9367\n",
      "100%|██████████| 24/24 [00:00<00:00, 46.81it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9581\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9667\n",
      "100%|██████████| 24/24 [00:00<00:00, 50.68it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9575\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9333\n",
      "100%|██████████| 24/24 [00:00<00:00, 43.56it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9599\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9700\n",
      "100%|██████████| 24/24 [00:00<00:00, 43.35it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9652\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9667\n",
      "100%|██████████| 24/24 [00:00<00:00, 31.94it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9660\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9500\n",
      "100%|██████████| 24/24 [00:00<00:00, 45.66it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9663\n",
      "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9667\n",
      "-- >> End of training phase << --\n",
      "Training completed\n",
      "\n",
      "Computing Fisher Information for experience 4...\n",
      "Computing Empirical Fisher Information for 200 samples...\n",
      "Processed 100/200 samples...\n",
      "Processed 200/200 samples...\n",
      "Empirical Fisher Information computed successfully for 200 samples!\n",
      "\n",
      "Fisher Information Statistics for Experience 4:\n",
      "  features.0.weight: Mean=0.000012, Max=0.002095\n",
      "  features.0.bias: Mean=0.000013, Max=0.000344\n",
      "  classifier.weight: Mean=0.000314, Max=0.071911\n",
      "  classifier.bias: Mean=0.001410, Max=0.007334\n",
      "\n",
      "Saving top 10% important weights for experience 4...\n",
      "--- Identifying and saving top 10.0% of weights ---\n",
      "Threshold for top 10.0% weights: 0.000020\n",
      "Found 40,705 important weights.\n",
      "Saving masks and values to 'important_weights_exp4.pt'\n",
      "\n",
      "============================================================\n",
      "Evaluating on all test experiences (0 to 4)...\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Evaluating on Test Experience 0 ---\n",
      "Restoring important weights from experience 0...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp0.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 73.66it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5206\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5206\n",
      "Results on test experience 0: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9666666666666667, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.966271186440678, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5205673758865248, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.5205673758865248, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.0019588638589618022, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.32123799359658484, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.9884189325276939}\n",
      "Completed evaluation on test experience 0\n",
      "\n",
      "--- Evaluating on Test Experience 1 ---\n",
      "Restoring important weights from experience 1...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp1.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 76.71it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2297\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2297\n",
      "Results on test experience 1: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9666666666666667, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.966271186440678, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5205673758865248, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.2296767874632713, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.2296767874632713, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.32123799359658484, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.9884189325276939}\n",
      "Completed evaluation on test experience 1\n",
      "\n",
      "--- Evaluating on Test Experience 2 ---\n",
      "Restoring important weights from experience 2...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp2.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 75.10it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2807\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2807\n",
      "Results on test experience 2: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9666666666666667, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.966271186440678, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5205673758865248, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.28068303094983993, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.2296767874632713, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.28068303094983993, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.9884189325276939}\n",
      "Completed evaluation on test experience 2\n",
      "\n",
      "--- Evaluating on Test Experience 3 ---\n",
      "Restoring important weights from experience 3...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp3.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 71.61it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.6027\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.6027\n",
      "Results on test experience 3: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9666666666666667, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.966271186440678, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5205673758865248, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.6027190332326284, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.2296767874632713, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.28068303094983993, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.6027190332326284}\n",
      "Completed evaluation on test experience 3\n",
      "\n",
      "--- Evaluating on Test Experience 4 ---\n",
      "Restoring important weights from experience 4...\n",
      "\n",
      "--- Restoring important weights from 'important_weights_exp4.pt' ---\n",
      "Restored 40,705 weights into the model.\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 76.57it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9672\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.9672\n",
      "Results on test experience 4: {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9666666666666667, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.966271186440678, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5205673758865248, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.9672213817448311, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.2296767874632713, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.28068303094983993, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.6027190332326284, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004': 0.9672213817448311}\n",
      "Completed evaluation on test experience 4\n",
      "\n",
      "Computing accuracy on the whole test set (experiences 0-4)...\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 22/22 [00:00<00:00, 83.60it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0024\n",
      "-- Starting eval on experience 1 (Task 0) from test stream --\n",
      "100%|██████████| 21/21 [00:00<00:00, 66.31it/s]\n",
      "> Eval on experience 1 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
      "-- Starting eval on experience 2 (Task 0) from test stream --\n",
      "100%|██████████| 19/19 [00:00<00:00, 66.88it/s]\n",
      "> Eval on experience 2 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0032\n",
      "-- Starting eval on experience 3 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 77.59it/s]\n",
      "> Eval on experience 3 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3917\n",
      "-- Starting eval on experience 4 (Task 0) from test stream --\n",
      "100%|██████████| 20/20 [00:00<00:00, 77.57it/s]\n",
      "> Eval on experience 4 (Task 0) from test stream ended.\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9672\n",
      "-- >> End of eval phase << --\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2707\n",
      "\n",
      "============================================================\n",
      "Training and evaluation completed!\n",
      "Model saved as final_splitmnist_model.pth\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics,\\\n",
    "    loss_metrics, timing_metrics, cpu_usage_metrics, StreamConfusionMatrix,\\\n",
    "    disk_usage_metrics, gpu_usage_metrics\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training import Naive\n",
    "from wandb_logger import WandBLogger\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch \n",
    "import copy\n",
    "\n",
    "from fisher_info import compute_empirical_fisher_information, plot_fisher_information_detailed, plot_fisher_information_heatmap\n",
    "\n",
    "\n",
    "\n",
    "# Create benchmark\n",
    "benchmark = SplitMNIST(n_experiences=5, return_task_id=False, seed=42, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create model\n",
    "model = SimpleMLP(num_classes=benchmark.n_classes).to(device)\n",
    "print(model)\n",
    "\n",
    "# Setup loggers\n",
    "tb_logger = WandBLogger(project_name=\"avalanche_tut_!\", run_name=\"run_1\")\n",
    "text_logger = TextLogger(open('log.txt', 'a'))\n",
    "interactive_logger = InteractiveLogger()\n",
    "\n",
    "# Setup evaluation plugin\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=[interactive_logger, text_logger, tb_logger]\n",
    ")\n",
    "\n",
    "# Setup continual learning strategy\n",
    "cl_strategy = Naive(\n",
    "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "    CrossEntropyLoss(), train_mb_size=500, train_epochs=10, eval_mb_size=100, device=device,\n",
    "    evaluator=eval_plugin\n",
    ")\n",
    "\n",
    "# Storage for important weights data\n",
    "important_weights_paths = {}  # Maps experience_id -> path to saved weights\n",
    "fisher_dicts = []\n",
    "\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "\n",
    "# Training loop\n",
    "for experience in benchmark.train_stream:\n",
    "    exp_id = experience.current_experience\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Start of experience: {exp_id}\")\n",
    "    print(f\"Current Classes: {experience.classes_in_this_experience}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Train on current experience\n",
    "    res = cl_strategy.train(experience, num_workers=4)\n",
    "    print('Training completed')\n",
    "    \n",
    "    # Compute Fisher Information after training\n",
    "    print(f'\\nComputing Fisher Information for experience {exp_id}...')\n",
    "    fisher_dict = compute_empirical_fisher_information(\n",
    "        model=model,\n",
    "        dataset=experience.dataset,\n",
    "        device=device,\n",
    "        num_samples=200\n",
    "    )\n",
    "    fisher_dicts.append(fisher_dict)\n",
    "    \n",
    "    # Plot Fisher Information\n",
    "    '''plot_fisher_information_detailed(\n",
    "        fisher_dict, \n",
    "        model=model, \n",
    "        save_path=f'fisher_detailed_exp{exp_id}.png'\n",
    "    )'''\n",
    "    \n",
    "    # Print Fisher statistics\n",
    "    print(f\"\\nFisher Information Statistics for Experience {exp_id}:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in fisher_dict:\n",
    "            print(f\"  {name}: Mean={fisher_dict[name].mean().item():.6f}, \"\n",
    "                  f\"Max={fisher_dict[name].max().item():.6f}\")\n",
    "    \n",
    "    # Save top 10% important weights for this experience\n",
    "    save_path = f\"important_weights_exp{exp_id}.pt\"\n",
    "    print(f\"\\nSaving top 10% important weights for experience {exp_id}...\")\n",
    "    save_top_n_percent_weights(\n",
    "        model=model,\n",
    "        fisher_dict=fisher_dict,\n",
    "        top_n_percent=10.0,\n",
    "        save_path=save_path\n",
    "    )\n",
    "    important_weights_paths[exp_id] = save_path\n",
    "    \n",
    "    # Evaluate on all test experiences seen so far\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f\"Evaluating on all test experiences (0 to {exp_id})...\")\n",
    "    print(f\"{\"=\"*60}\\n\")\n",
    "    \n",
    "    for test_exp_id in range(exp_id + 1):\n",
    "        print(f\"\\n--- Evaluating on Test Experience {test_exp_id} ---\")\n",
    "        \n",
    "        # Restore important weights for this test experience\n",
    "        if test_exp_id in important_weights_paths:\n",
    "            print(f\"Restoring important weights from experience {test_exp_id}...\")\n",
    "            restore_important_weights(\n",
    "                model=model,\n",
    "                load_path=important_weights_paths[test_exp_id]\n",
    "            )\n",
    "        \n",
    "        # Evaluate on the specific test experience\n",
    "        test_stream_subset = [benchmark.test_stream[test_exp_id]]\n",
    "        result = cl_strategy.eval(test_stream_subset, num_workers=4)\n",
    "        print(f\"Results on test experience {test_exp_id}: {result}\")\n",
    "        \n",
    "        print(f\"Completed evaluation on test experience {test_exp_id}\")\n",
    "    \n",
    "    # Store overall results\n",
    "    print(f'\\nComputing accuracy on the whole test set (experiences 0-{exp_id})...')\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream[:exp_id+1], num_workers=4))\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), \"final_splitmnist_model.pth\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training and evaluation completed!\")\n",
    "print(\"Model saved as final_splitmnist_model.pth\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d9c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b57d1f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results:\n",
      " [{'Top1_Acc_MB/train_phase/train_stream/Task000': 1.0, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.7966048164232136, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.9966903073286052, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.9966903073286052}, {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9213483146067416, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.45181570022334355, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.7546099290780142, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.8429155641087323, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.9343780607247796}, {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.935361216730038, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.34555624611559976, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.7380614657210401, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.6221190515669043, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.21057786483839372, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.9397011739594451}, {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.9781420765027322, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.4329803825002052, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5697399527186762, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.42734189846576026, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.002448579823702253, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.13660618996798293, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.9869083585095669}, {'Top1_Acc_MB/train_phase/train_stream/Task000': 0.8666666666666667, 'Top1_Acc_Epoch/train_phase/train_stream/Task000': 0.3261864406779661, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000': 0.5825059101654846, 'Top1_Acc_Stream/eval_phase/test_stream/Task000': 0.4366, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001': 0.03672869735553379, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002': 0.010138740661686232, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003': 0.5916414904330313, 'Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004': 0.940494200706001}]\n"
     ]
    }
   ],
   "source": [
    "print('All results:\\n', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
